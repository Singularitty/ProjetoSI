{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sistemas Inteligentes 2021/2022\n","\n","## Mini-projeto 3: Aprendizagem Automática\n","\n","## Relatório\n"]},{"cell_type":"markdown","metadata":{},"source":["## Grupo: 42\n","\n","Número:  53687       Nome:   Ariana Dias  \n","\n","Número:  51127       Nome:   Luís Ferreirinha"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Processamento dos dados"]},{"cell_type":"markdown","metadata":{},"source":["Para processarmos os dados vamos utilizar a biblioteca pandas e numpy"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Começamos por ler o ficheiro csv com os dados de treino e guarda-mos o conteúdo num dataframe."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df_train = pd.read_csv(\"train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["Vamos confirmar que os dados foram corretamente importados"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>N_Days</th>\n","      <th>Status</th>\n","      <th>Drug</th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","      <th>Ascites</th>\n","      <th>Hepatomegaly</th>\n","      <th>Spiders</th>\n","      <th>Edema</th>\n","      <th>Bilirubin</th>\n","      <th>Cholesterol</th>\n","      <th>Albumin</th>\n","      <th>Copper</th>\n","      <th>Alk_Phos</th>\n","      <th>SGOT</th>\n","      <th>Tryglicerides</th>\n","      <th>Platelets</th>\n","      <th>Prothrombin</th>\n","      <th>Stage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2644</td>\n","      <td>C</td>\n","      <td>D-penicillamine</td>\n","      <td>20296</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0.5</td>\n","      <td>369.510563</td>\n","      <td>3.85</td>\n","      <td>63.000000</td>\n","      <td>663.000000</td>\n","      <td>79.050000</td>\n","      <td>124.702128</td>\n","      <td>311.0</td>\n","      <td>9.7</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3492</td>\n","      <td>C</td>\n","      <td>Unknown</td>\n","      <td>21915</td>\n","      <td>F</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>N</td>\n","      <td>0.6</td>\n","      <td>369.510563</td>\n","      <td>4.38</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>269.0</td>\n","      <td>10.6</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1702</td>\n","      <td>C</td>\n","      <td>D-penicillamine</td>\n","      <td>18806</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>1.1</td>\n","      <td>414.000000</td>\n","      <td>3.44</td>\n","      <td>80.000000</td>\n","      <td>1003.000000</td>\n","      <td>99.000000</td>\n","      <td>55.000000</td>\n","      <td>271.0</td>\n","      <td>9.6</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3523</td>\n","      <td>C</td>\n","      <td>Unknown</td>\n","      <td>14610</td>\n","      <td>F</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>N</td>\n","      <td>0.6</td>\n","      <td>369.510563</td>\n","      <td>4.04</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>130.0</td>\n","      <td>11.2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>3428</td>\n","      <td>D</td>\n","      <td>Placebo</td>\n","      <td>13727</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>3.3</td>\n","      <td>299.000000</td>\n","      <td>3.55</td>\n","      <td>131.000000</td>\n","      <td>1029.000000</td>\n","      <td>119.350000</td>\n","      <td>50.000000</td>\n","      <td>199.0</td>\n","      <td>11.7</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>324</td>\n","      <td>2255</td>\n","      <td>C</td>\n","      <td>D-penicillamine</td>\n","      <td>22642</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0.6</td>\n","      <td>213.000000</td>\n","      <td>4.07</td>\n","      <td>12.000000</td>\n","      <td>5300.000000</td>\n","      <td>57.350000</td>\n","      <td>68.000000</td>\n","      <td>240.0</td>\n","      <td>11.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>325</td>\n","      <td>1899</td>\n","      <td>C</td>\n","      <td>Unknown</td>\n","      <td>14975</td>\n","      <td>M</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>N</td>\n","      <td>1.7</td>\n","      <td>369.510563</td>\n","      <td>3.66</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>92.0</td>\n","      <td>11.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>326</td>\n","      <td>1152</td>\n","      <td>D</td>\n","      <td>D-penicillamine</td>\n","      <td>25546</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>2.3</td>\n","      <td>586.000000</td>\n","      <td>3.01</td>\n","      <td>243.000000</td>\n","      <td>2276.000000</td>\n","      <td>114.700000</td>\n","      <td>126.000000</td>\n","      <td>339.0</td>\n","      <td>10.9</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>327</td>\n","      <td>71</td>\n","      <td>D</td>\n","      <td>D-penicillamine</td>\n","      <td>18972</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>S</td>\n","      <td>12.2</td>\n","      <td>394.000000</td>\n","      <td>3.08</td>\n","      <td>111.000000</td>\n","      <td>2132.000000</td>\n","      <td>155.000000</td>\n","      <td>243.000000</td>\n","      <td>165.0</td>\n","      <td>11.6</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>328</td>\n","      <td>1874</td>\n","      <td>C</td>\n","      <td>Placebo</td>\n","      <td>24257</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>S</td>\n","      <td>0.6</td>\n","      <td>280.000000</td>\n","      <td>3.35</td>\n","      <td>97.648387</td>\n","      <td>1093.000000</td>\n","      <td>128.650000</td>\n","      <td>81.000000</td>\n","      <td>295.0</td>\n","      <td>9.8</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>329 rows × 20 columns</p>\n","</div>"],"text/plain":["      ID  N_Days Status             Drug    Age Sex  Ascites Hepatomegaly  \\\n","0      0    2644      C  D-penicillamine  20296   F        N            N   \n","1      1    3492      C          Unknown  21915   F  Unknown      Unknown   \n","2      2    1702      C  D-penicillamine  18806   F        N            N   \n","3      3    3523      C          Unknown  14610   F  Unknown      Unknown   \n","4      4    3428      D          Placebo  13727   F        N            Y   \n","..   ...     ...    ...              ...    ...  ..      ...          ...   \n","324  324    2255      C  D-penicillamine  22642   F        N            N   \n","325  325    1899      C          Unknown  14975   M  Unknown      Unknown   \n","326  326    1152      D  D-penicillamine  25546   M        N            Y   \n","327  327      71      D  D-penicillamine  18972   F        N            Y   \n","328  328    1874      C          Placebo  24257   F        N            N   \n","\n","     Spiders Edema  Bilirubin  Cholesterol  Albumin      Copper     Alk_Phos  \\\n","0          N     N        0.5   369.510563     3.85   63.000000   663.000000   \n","1    Unknown     N        0.6   369.510563     4.38   97.648387  1982.655769   \n","2          N     N        1.1   414.000000     3.44   80.000000  1003.000000   \n","3    Unknown     N        0.6   369.510563     4.04   97.648387  1982.655769   \n","4          Y     Y        3.3   299.000000     3.55  131.000000  1029.000000   \n","..       ...   ...        ...          ...      ...         ...          ...   \n","324        N     N        0.6   213.000000     4.07   12.000000  5300.000000   \n","325  Unknown     N        1.7   369.510563     3.66   97.648387  1982.655769   \n","326        N     N        2.3   586.000000     3.01  243.000000  2276.000000   \n","327        Y     S       12.2   394.000000     3.08  111.000000  2132.000000   \n","328        N     S        0.6   280.000000     3.35   97.648387  1093.000000   \n","\n","           SGOT  Tryglicerides  Platelets  Prothrombin  Stage  \n","0     79.050000     124.702128      311.0          9.7    1.0  \n","1    122.556346     124.702128      269.0         10.6    2.0  \n","2     99.000000      55.000000      271.0          9.6    1.0  \n","3    122.556346     124.702128      130.0         11.2    2.0  \n","4    119.350000      50.000000      199.0         11.7    3.0  \n","..          ...            ...        ...          ...    ...  \n","324   57.350000      68.000000      240.0         11.0    1.0  \n","325  122.556346     124.702128       92.0         11.0    4.0  \n","326  114.700000     126.000000      339.0         10.9    3.0  \n","327  155.000000     243.000000      165.0         11.6    4.0  \n","328  128.650000      81.000000      295.0          9.8    2.0  \n","\n","[329 rows x 20 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"markdown","metadata":{},"source":["Vamos extrair os valores das classes"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array([1., 2., 1., 2., 3., 4., 3., 4., 4., 4., 4., 1., 1., 3., 3., 1., 3.,\n","       4., 4., 4., 1., 2., 2., 2., 3., 2., 4., 4., 4., 4., 3., 1., 4., 4.,\n","       3., 3., 4., 3., 3., 2., 4., 3., 2., 2., 3., 3., 4., 3., 3., 2., 4.,\n","       4., 2., 2., 2., 3., 4., 1., 4., 1., 3., 2., 2., 3., 3., 4., 4., 4.,\n","       3., 3., 3., 4., 3., 3., 3., 2., 2., 4., 4., 3., 3., 3., 2., 2., 2.,\n","       4., 3., 4., 4., 3., 4., 4., 3., 4., 3., 3., 4., 3., 4., 2., 2., 3.,\n","       2., 2., 3., 2., 2., 4., 3., 4., 4., 4., 3., 2., 4., 2., 2., 4., 4.,\n","       3., 4., 4., 4., 3., 1., 2., 2., 4., 3., 2., 4., 2., 4., 4., 4., 4.,\n","       3., 3., 4., 2., 2., 3., 2., 2., 2., 3., 4., 4., 4., 3., 4., 4., 4.,\n","       3., 4., 2., 4., 4., 2., 3., 4., 2., 2., 3., 3., 3., 4., 4., 4., 3.,\n","       2., 1., 3., 3., 4., 3., 3., 4., 2., 3., 3., 2., 3., 4., 4., 2., 4.,\n","       2., 3., 3., 1., 4., 4., 1., 4., 2., 3., 4., 4., 3., 2., 3., 2., 4.,\n","       2., 3., 3., 4., 3., 2., 3., 4., 3., 2., 4., 4., 3., 3., 3., 4., 3.,\n","       4., 3., 4., 3., 4., 4., 4., 3., 3., 3., 4., 3., 4., 3., 4., 3., 3.,\n","       2., 2., 3., 3., 3., 3., 2., 3., 4., 4., 3., 2., 3., 4., 4., 2., 2.,\n","       2., 3., 1., 2., 3., 3., 4., 3., 3., 4., 4., 2., 3., 3., 3., 3., 4.,\n","       4., 2., 3., 3., 3., 3., 3., 4., 4., 2., 3., 4., 1., 3., 3., 2., 3.,\n","       4., 3., 4., 4., 4., 3., 3., 4., 2., 2., 4., 3., 3., 4., 2., 2., 4.,\n","       3., 4., 3., 3., 3., 3., 3., 1., 3., 4., 2., 3., 4., 3., 2., 2., 4.,\n","       3., 1., 4., 3., 4., 2.])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["y_train = df_train[\"Stage\"].values\n","y_train"]},{"cell_type":"markdown","metadata":{},"source":["Como este conjunto de dados contém dados categóricos misturados com contínuos vamos ter de separar os categóricos e converter em dados binários utilizando o get_dummies()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Status</th>\n","      <th>Drug</th>\n","      <th>Sex</th>\n","      <th>Ascites</th>\n","      <th>Hepatomegaly</th>\n","      <th>Spiders</th>\n","      <th>Edema</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C</td>\n","      <td>D-penicillamine</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C</td>\n","      <td>Unknown</td>\n","      <td>F</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>D-penicillamine</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C</td>\n","      <td>Unknown</td>\n","      <td>F</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>D</td>\n","      <td>Placebo</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>C</td>\n","      <td>D-penicillamine</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>C</td>\n","      <td>Unknown</td>\n","      <td>M</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>Unknown</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>D</td>\n","      <td>D-penicillamine</td>\n","      <td>M</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>D</td>\n","      <td>D-penicillamine</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>C</td>\n","      <td>Placebo</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>329 rows × 7 columns</p>\n","</div>"],"text/plain":["    Status             Drug Sex  Ascites Hepatomegaly  Spiders Edema\n","0        C  D-penicillamine   F        N            N        N     N\n","1        C          Unknown   F  Unknown      Unknown  Unknown     N\n","2        C  D-penicillamine   F        N            N        N     N\n","3        C          Unknown   F  Unknown      Unknown  Unknown     N\n","4        D          Placebo   F        N            Y        Y     Y\n","..     ...              ...  ..      ...          ...      ...   ...\n","324      C  D-penicillamine   F        N            N        N     N\n","325      C          Unknown   M  Unknown      Unknown  Unknown     N\n","326      D  D-penicillamine   M        N            Y        N     N\n","327      D  D-penicillamine   F        N            Y        Y     S\n","328      C          Placebo   F        N            N        N     S\n","\n","[329 rows x 7 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_categorical = df_train.select_dtypes([object])\n","df_categorical"]},{"cell_type":"markdown","metadata":{},"source":["Também guardamos os atributos com variáveis continuas num outro dataframe, retiramos a coluna ID pois esta é uma variável independente e também a Stage porque representa as classes."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>N_Days</th>\n","      <th>Age</th>\n","      <th>Bilirubin</th>\n","      <th>Cholesterol</th>\n","      <th>Albumin</th>\n","      <th>Copper</th>\n","      <th>Alk_Phos</th>\n","      <th>SGOT</th>\n","      <th>Tryglicerides</th>\n","      <th>Platelets</th>\n","      <th>Prothrombin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2644</td>\n","      <td>20296</td>\n","      <td>0.5</td>\n","      <td>369.510563</td>\n","      <td>3.85</td>\n","      <td>63.000000</td>\n","      <td>663.000000</td>\n","      <td>79.050000</td>\n","      <td>124.702128</td>\n","      <td>311.0</td>\n","      <td>9.7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3492</td>\n","      <td>21915</td>\n","      <td>0.6</td>\n","      <td>369.510563</td>\n","      <td>4.38</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>269.0</td>\n","      <td>10.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1702</td>\n","      <td>18806</td>\n","      <td>1.1</td>\n","      <td>414.000000</td>\n","      <td>3.44</td>\n","      <td>80.000000</td>\n","      <td>1003.000000</td>\n","      <td>99.000000</td>\n","      <td>55.000000</td>\n","      <td>271.0</td>\n","      <td>9.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3523</td>\n","      <td>14610</td>\n","      <td>0.6</td>\n","      <td>369.510563</td>\n","      <td>4.04</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>130.0</td>\n","      <td>11.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3428</td>\n","      <td>13727</td>\n","      <td>3.3</td>\n","      <td>299.000000</td>\n","      <td>3.55</td>\n","      <td>131.000000</td>\n","      <td>1029.000000</td>\n","      <td>119.350000</td>\n","      <td>50.000000</td>\n","      <td>199.0</td>\n","      <td>11.7</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>2255</td>\n","      <td>22642</td>\n","      <td>0.6</td>\n","      <td>213.000000</td>\n","      <td>4.07</td>\n","      <td>12.000000</td>\n","      <td>5300.000000</td>\n","      <td>57.350000</td>\n","      <td>68.000000</td>\n","      <td>240.0</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>1899</td>\n","      <td>14975</td>\n","      <td>1.7</td>\n","      <td>369.510563</td>\n","      <td>3.66</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>92.0</td>\n","      <td>11.0</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>1152</td>\n","      <td>25546</td>\n","      <td>2.3</td>\n","      <td>586.000000</td>\n","      <td>3.01</td>\n","      <td>243.000000</td>\n","      <td>2276.000000</td>\n","      <td>114.700000</td>\n","      <td>126.000000</td>\n","      <td>339.0</td>\n","      <td>10.9</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>71</td>\n","      <td>18972</td>\n","      <td>12.2</td>\n","      <td>394.000000</td>\n","      <td>3.08</td>\n","      <td>111.000000</td>\n","      <td>2132.000000</td>\n","      <td>155.000000</td>\n","      <td>243.000000</td>\n","      <td>165.0</td>\n","      <td>11.6</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>1874</td>\n","      <td>24257</td>\n","      <td>0.6</td>\n","      <td>280.000000</td>\n","      <td>3.35</td>\n","      <td>97.648387</td>\n","      <td>1093.000000</td>\n","      <td>128.650000</td>\n","      <td>81.000000</td>\n","      <td>295.0</td>\n","      <td>9.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>329 rows × 11 columns</p>\n","</div>"],"text/plain":["     N_Days    Age  Bilirubin  Cholesterol  Albumin      Copper     Alk_Phos  \\\n","0      2644  20296        0.5   369.510563     3.85   63.000000   663.000000   \n","1      3492  21915        0.6   369.510563     4.38   97.648387  1982.655769   \n","2      1702  18806        1.1   414.000000     3.44   80.000000  1003.000000   \n","3      3523  14610        0.6   369.510563     4.04   97.648387  1982.655769   \n","4      3428  13727        3.3   299.000000     3.55  131.000000  1029.000000   \n","..      ...    ...        ...          ...      ...         ...          ...   \n","324    2255  22642        0.6   213.000000     4.07   12.000000  5300.000000   \n","325    1899  14975        1.7   369.510563     3.66   97.648387  1982.655769   \n","326    1152  25546        2.3   586.000000     3.01  243.000000  2276.000000   \n","327      71  18972       12.2   394.000000     3.08  111.000000  2132.000000   \n","328    1874  24257        0.6   280.000000     3.35   97.648387  1093.000000   \n","\n","           SGOT  Tryglicerides  Platelets  Prothrombin  \n","0     79.050000     124.702128      311.0          9.7  \n","1    122.556346     124.702128      269.0         10.6  \n","2     99.000000      55.000000      271.0          9.6  \n","3    122.556346     124.702128      130.0         11.2  \n","4    119.350000      50.000000      199.0         11.7  \n","..          ...            ...        ...          ...  \n","324   57.350000      68.000000      240.0         11.0  \n","325  122.556346     124.702128       92.0         11.0  \n","326  114.700000     126.000000      339.0         10.9  \n","327  155.000000     243.000000      165.0         11.6  \n","328  128.650000      81.000000      295.0          9.8  \n","\n","[329 rows x 11 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df_numerical = df_train.select_dtypes([np.number]).drop(columns=[\"ID\",\"Stage\"])\n","df_numerical"]},{"cell_type":"markdown","metadata":{},"source":["Obtemos os dummies do dataframe das categóricas"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Status_C</th>\n","      <th>Status_CL</th>\n","      <th>Status_D</th>\n","      <th>Drug_D-penicillamine</th>\n","      <th>Drug_Placebo</th>\n","      <th>Drug_Unknown</th>\n","      <th>Sex_F</th>\n","      <th>Sex_M</th>\n","      <th>Ascites_N</th>\n","      <th>Ascites_Unknown</th>\n","      <th>Ascites_Y</th>\n","      <th>Hepatomegaly_N</th>\n","      <th>Hepatomegaly_Unknown</th>\n","      <th>Hepatomegaly_Y</th>\n","      <th>Spiders_N</th>\n","      <th>Spiders_Unknown</th>\n","      <th>Spiders_Y</th>\n","      <th>Edema_N</th>\n","      <th>Edema_S</th>\n","      <th>Edema_Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>329 rows × 20 columns</p>\n","</div>"],"text/plain":["     Status_C  Status_CL  Status_D  Drug_D-penicillamine  Drug_Placebo  \\\n","0           1          0         0                     1             0   \n","1           1          0         0                     0             0   \n","2           1          0         0                     1             0   \n","3           1          0         0                     0             0   \n","4           0          0         1                     0             1   \n","..        ...        ...       ...                   ...           ...   \n","324         1          0         0                     1             0   \n","325         1          0         0                     0             0   \n","326         0          0         1                     1             0   \n","327         0          0         1                     1             0   \n","328         1          0         0                     0             1   \n","\n","     Drug_Unknown  Sex_F  Sex_M  Ascites_N  Ascites_Unknown  Ascites_Y  \\\n","0               0      1      0          1                0          0   \n","1               1      1      0          0                1          0   \n","2               0      1      0          1                0          0   \n","3               1      1      0          0                1          0   \n","4               0      1      0          1                0          0   \n","..            ...    ...    ...        ...              ...        ...   \n","324             0      1      0          1                0          0   \n","325             1      0      1          0                1          0   \n","326             0      0      1          1                0          0   \n","327             0      1      0          1                0          0   \n","328             0      1      0          1                0          0   \n","\n","     Hepatomegaly_N  Hepatomegaly_Unknown  Hepatomegaly_Y  Spiders_N  \\\n","0                 1                     0               0          1   \n","1                 0                     1               0          0   \n","2                 1                     0               0          1   \n","3                 0                     1               0          0   \n","4                 0                     0               1          0   \n","..              ...                   ...             ...        ...   \n","324               1                     0               0          1   \n","325               0                     1               0          0   \n","326               0                     0               1          1   \n","327               0                     0               1          0   \n","328               1                     0               0          1   \n","\n","     Spiders_Unknown  Spiders_Y  Edema_N  Edema_S  Edema_Y  \n","0                  0          0        1        0        0  \n","1                  1          0        1        0        0  \n","2                  0          0        1        0        0  \n","3                  1          0        1        0        0  \n","4                  0          1        0        0        1  \n","..               ...        ...      ...      ...      ...  \n","324                0          0        1        0        0  \n","325                1          0        1        0        0  \n","326                0          0        1        0        0  \n","327                0          1        0        1        0  \n","328                0          0        0        1        0  \n","\n","[329 rows x 20 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_categorical_dummies = pd.get_dummies(df_categorical)\n","\n","column_names_dum = np.array(df_categorical_dummies.columns)\n","\n","df_categorical_dummies"]},{"cell_type":"markdown","metadata":{},"source":["E agora juntam-mos os dois dataframes"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>N_Days</th>\n","      <th>Age</th>\n","      <th>Bilirubin</th>\n","      <th>Cholesterol</th>\n","      <th>Albumin</th>\n","      <th>Copper</th>\n","      <th>Alk_Phos</th>\n","      <th>SGOT</th>\n","      <th>Tryglicerides</th>\n","      <th>Platelets</th>\n","      <th>...</th>\n","      <th>Ascites_Y</th>\n","      <th>Hepatomegaly_N</th>\n","      <th>Hepatomegaly_Unknown</th>\n","      <th>Hepatomegaly_Y</th>\n","      <th>Spiders_N</th>\n","      <th>Spiders_Unknown</th>\n","      <th>Spiders_Y</th>\n","      <th>Edema_N</th>\n","      <th>Edema_S</th>\n","      <th>Edema_Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2644</td>\n","      <td>20296</td>\n","      <td>0.5</td>\n","      <td>369.510563</td>\n","      <td>3.85</td>\n","      <td>63.000000</td>\n","      <td>663.000000</td>\n","      <td>79.050000</td>\n","      <td>124.702128</td>\n","      <td>311.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3492</td>\n","      <td>21915</td>\n","      <td>0.6</td>\n","      <td>369.510563</td>\n","      <td>4.38</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>269.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1702</td>\n","      <td>18806</td>\n","      <td>1.1</td>\n","      <td>414.000000</td>\n","      <td>3.44</td>\n","      <td>80.000000</td>\n","      <td>1003.000000</td>\n","      <td>99.000000</td>\n","      <td>55.000000</td>\n","      <td>271.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3523</td>\n","      <td>14610</td>\n","      <td>0.6</td>\n","      <td>369.510563</td>\n","      <td>4.04</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>130.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3428</td>\n","      <td>13727</td>\n","      <td>3.3</td>\n","      <td>299.000000</td>\n","      <td>3.55</td>\n","      <td>131.000000</td>\n","      <td>1029.000000</td>\n","      <td>119.350000</td>\n","      <td>50.000000</td>\n","      <td>199.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>324</th>\n","      <td>2255</td>\n","      <td>22642</td>\n","      <td>0.6</td>\n","      <td>213.000000</td>\n","      <td>4.07</td>\n","      <td>12.000000</td>\n","      <td>5300.000000</td>\n","      <td>57.350000</td>\n","      <td>68.000000</td>\n","      <td>240.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>1899</td>\n","      <td>14975</td>\n","      <td>1.7</td>\n","      <td>369.510563</td>\n","      <td>3.66</td>\n","      <td>97.648387</td>\n","      <td>1982.655769</td>\n","      <td>122.556346</td>\n","      <td>124.702128</td>\n","      <td>92.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>1152</td>\n","      <td>25546</td>\n","      <td>2.3</td>\n","      <td>586.000000</td>\n","      <td>3.01</td>\n","      <td>243.000000</td>\n","      <td>2276.000000</td>\n","      <td>114.700000</td>\n","      <td>126.000000</td>\n","      <td>339.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>71</td>\n","      <td>18972</td>\n","      <td>12.2</td>\n","      <td>394.000000</td>\n","      <td>3.08</td>\n","      <td>111.000000</td>\n","      <td>2132.000000</td>\n","      <td>155.000000</td>\n","      <td>243.000000</td>\n","      <td>165.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>1874</td>\n","      <td>24257</td>\n","      <td>0.6</td>\n","      <td>280.000000</td>\n","      <td>3.35</td>\n","      <td>97.648387</td>\n","      <td>1093.000000</td>\n","      <td>128.650000</td>\n","      <td>81.000000</td>\n","      <td>295.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>329 rows × 31 columns</p>\n","</div>"],"text/plain":["     N_Days    Age  Bilirubin  Cholesterol  Albumin      Copper     Alk_Phos  \\\n","0      2644  20296        0.5   369.510563     3.85   63.000000   663.000000   \n","1      3492  21915        0.6   369.510563     4.38   97.648387  1982.655769   \n","2      1702  18806        1.1   414.000000     3.44   80.000000  1003.000000   \n","3      3523  14610        0.6   369.510563     4.04   97.648387  1982.655769   \n","4      3428  13727        3.3   299.000000     3.55  131.000000  1029.000000   \n","..      ...    ...        ...          ...      ...         ...          ...   \n","324    2255  22642        0.6   213.000000     4.07   12.000000  5300.000000   \n","325    1899  14975        1.7   369.510563     3.66   97.648387  1982.655769   \n","326    1152  25546        2.3   586.000000     3.01  243.000000  2276.000000   \n","327      71  18972       12.2   394.000000     3.08  111.000000  2132.000000   \n","328    1874  24257        0.6   280.000000     3.35   97.648387  1093.000000   \n","\n","           SGOT  Tryglicerides  Platelets  ...  Ascites_Y  Hepatomegaly_N  \\\n","0     79.050000     124.702128      311.0  ...          0               1   \n","1    122.556346     124.702128      269.0  ...          0               0   \n","2     99.000000      55.000000      271.0  ...          0               1   \n","3    122.556346     124.702128      130.0  ...          0               0   \n","4    119.350000      50.000000      199.0  ...          0               0   \n","..          ...            ...        ...  ...        ...             ...   \n","324   57.350000      68.000000      240.0  ...          0               1   \n","325  122.556346     124.702128       92.0  ...          0               0   \n","326  114.700000     126.000000      339.0  ...          0               0   \n","327  155.000000     243.000000      165.0  ...          0               0   \n","328  128.650000      81.000000      295.0  ...          0               1   \n","\n","     Hepatomegaly_Unknown  Hepatomegaly_Y  Spiders_N  Spiders_Unknown  \\\n","0                       0               0          1                0   \n","1                       1               0          0                1   \n","2                       0               0          1                0   \n","3                       1               0          0                1   \n","4                       0               1          0                0   \n","..                    ...             ...        ...              ...   \n","324                     0               0          1                0   \n","325                     1               0          0                1   \n","326                     0               1          1                0   \n","327                     0               1          0                0   \n","328                     0               0          1                0   \n","\n","     Spiders_Y  Edema_N  Edema_S  Edema_Y  \n","0            0        1        0        0  \n","1            0        1        0        0  \n","2            0        1        0        0  \n","3            0        1        0        0  \n","4            1        0        0        1  \n","..         ...      ...      ...      ...  \n","324          0        1        0        0  \n","325          0        1        0        0  \n","326          0        1        0        0  \n","327          1        0        1        0  \n","328          0        0        1        0  \n","\n","[329 rows x 31 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_train_processado = pd.concat([df_numerical, df_categorical_dummies], axis=1, join='inner')\n","\n","df_train_processado"]},{"cell_type":"markdown","metadata":{},"source":["E assim obtemos a matrix com os valores"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["array([[2.6440e+03, 2.0296e+04, 5.0000e-01, ..., 1.0000e+00, 0.0000e+00,\n","        0.0000e+00],\n","       [3.4920e+03, 2.1915e+04, 6.0000e-01, ..., 1.0000e+00, 0.0000e+00,\n","        0.0000e+00],\n","       [1.7020e+03, 1.8806e+04, 1.1000e+00, ..., 1.0000e+00, 0.0000e+00,\n","        0.0000e+00],\n","       ...,\n","       [1.1520e+03, 2.5546e+04, 2.3000e+00, ..., 1.0000e+00, 0.0000e+00,\n","        0.0000e+00],\n","       [7.1000e+01, 1.8972e+04, 1.2200e+01, ..., 0.0000e+00, 1.0000e+00,\n","        0.0000e+00],\n","       [1.8740e+03, 2.4257e+04, 6.0000e-01, ..., 0.0000e+00, 1.0000e+00,\n","        0.0000e+00]])"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["X_train = df_train_processado.values\n","X_train"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Ajustamento dos modelos\n","\n","\n","### 2.1. Teste de modelos e validação"]},{"cell_type":"markdown","metadata":{},"source":["Vamos agora criar os diferentes modelos e avaliar a sua performance, após criarmos cada um dos modelos vamos ajustá-los ao problema e tentar obter as melhores classificações para cada um dos classificadores, portanto vamos utilizar o k-folds para validar os modelos e a average cross-validation accuracy como métrica de desempenho para cada classificador.  \n","\n","Para cada classificador iremos guardar as accuracies obtidas para depois pudermos comparar"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["scores_finais = {}"]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree  "]},{"cell_type":"markdown","metadata":{},"source":["Vamos começar por criar uma Decision Tree (sem ajustar parâmetros) e treinar com todos os dados de treino."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV accuracy:\n","\t0.30303030303030304\n","\t0.48484848484848486\n","\t0.3333333333333333\n","\t0.2727272727272727\n","\t0.42424242424242425\n","\t0.6060606060606061\n","\t0.3939393939393939\n","\t0.3333333333333333\n","\t0.30303030303030304\n","\t0.4375\n","Average CV accuracy: 0.389 +/- 0.097\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier, plot_tree\n","from sklearn.model_selection import cross_val_score\n","\n","import matplotlib.pyplot as plt\n","\n","dtc = DecisionTreeClassifier(criterion=\"entropy\")\n","\n","scores = cross_val_score(dtc,\n","                         X=X_train,\n","                         y=y_train,\n","                         cv=10\n","                        )\n","print('CV accuracy:', *scores, sep='\\n\\t')\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))"]},{"cell_type":"markdown","metadata":{},"source":["Uma decision tree sem qualquer ajuste dos seus parâmetros tem uma accuracy terrível. Para melhorar-mos esta accuracy podemos ajustar os seguintes parâmetros.\n","```\n","max_depth\n","min_samples_split\n","min_samples_leaf\n","```\n","Mas primeiro vamos tentar reduzir a dimensão do problema, para fazer-mos isto vamos eliminar os atributos de menor importância do nosso conjunto de dados utilizando Recursive Feature Elimination (RFE). Podemos importar esta classe do módulo feature_selection do sklearn."]},{"cell_type":"markdown","metadata":{},"source":["O RFE vai tentar determinar a importância de cada um dos atributos fazendo prune dos atríbutos menos importantes do conjunto atual de atríbutos, este procedimento depois é repetido recursivamente até se atingir o número de features especifícado."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["RFE(estimator=DecisionTreeClassifier(criterion='entropy'))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Exemplo do RFE\n","from sklearn.feature_selection import RFE\n","# Passamos o nosso estimador como parâmetro e o número de atributos a selecionar\n","# Como não indicamos o número de atributos este será metade por defeito\n","rfe_teste = RFE(estimator=DecisionTreeClassifier(criterion=\"entropy\"))\n","rfe_teste.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Podemos ver o ranking de cada um dos atributos do nosso problema, os mais relevântes terão um número menor"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2, 12, 14, 16, 17, 15,\n","       13, 11,  1,  1,  4,  3,  1,  1,  5,  6,  7, 10,  8,  9])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["rfe_teste.ranking_"]},{"cell_type":"markdown","metadata":{},"source":["E podemos obter a máscara que nos vai permitir selecionar os melhores atributos para treinar-mos os nosso modelo"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True,  True, False, False, False, False, False, False, False,\n","       False,  True,  True, False, False,  True,  True, False, False,\n","       False, False, False, False])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["rfe_teste.support_"]},{"cell_type":"markdown","metadata":{},"source":["Fazendo um teste simples podemos observar que a nossa accuracy média aumentou sem termos alterado nenhum dos pârametros da decision tree!"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV accuracy:\n","\t0.3939393939393939\n","\t0.36363636363636365\n","\t0.3939393939393939\n","\t0.30303030303030304\n","\t0.3939393939393939\n","\t0.5454545454545454\n","\t0.36363636363636365\n","\t0.36363636363636365\n","\t0.36363636363636365\n","\t0.40625\n","Average CV accuracy: 0.389 +/- 0.059\n"]}],"source":["scores = cross_val_score(dtc,\n","                        # IMPORTANTE! Temos de transformar os dados de treino usando a mascara que rfe obteve!\n","                         X=rfe_teste.transform(X_train),\n","                         y=y_train,\n","                         cv=10\n","                        )\n","print('CV accuracy:', *scores, sep='\\n\\t')\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))"]},{"cell_type":"markdown","metadata":{},"source":["O RFE permite-nos especificar o número de features que desejamos fazer prune, por default este faz prune de metade dos features. Como não sabemos o número ideal de features vamos ter de o procurar."]},{"cell_type":"markdown","metadata":{},"source":["Agora podemos voltar aos parâmetros da decision tree. Para melhorar-mos este classificador vamos ter de ajustar os parâmetros ao nosso problema, como já referimos anteriormente vamos apenas ajustar três parâmetros (que foram dados nas aulas), uma forma simples de o fazer seria utilizando 3 ciclos for para variar cada um dos parâmetros e calcular a average accuracy para cada ciclo. Como temos também de descobrir o melhor número de atributos a remover e como o RFE depende do estimador, vamos ter de fazer uma procura em 4 dimensões com 4 ciclos for.\n","\n","Portanto o nosso algoritmo de procura será:\n","- Variar max_depth, min_samples_split, min_samples_leaf\n","    - Variar o número de features a remover\n","        - Determinar os features a remover usando RFE\n","        - Treinar modelo com dados de treino transformados pelo RFE\n","        - Validar utilizando o k-folds e guardar a accuracy média para esta combinação de parâmetros num dicionário  \n","  \n","- Obter o valor máximo de accuracy e os parâmetros correspondentes"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["12"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Queremos descobrir a depth máxima para pudermos determinar o dominio de procura deste parametro\n","dtc.fit(X_train,y_train)\n","dtc.get_depth()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Atencao! Esta procura demora cerca de 18 minutos!\n","\n","scores = {}\n","\n","param_grid = {'max_depth' : [i for i in range(2,10)], 'min_samples_split' : [i for i in range(2,30,2)], 'min_samples_leaf' : [i for i in range(2,30,2)],\n","              'n_features_to_select' : [i for i in range(5,20,2)]}\n","\n","\n","for depth in param_grid[\"max_depth\"]:\n","    for samples_split in param_grid[\"min_samples_split\"]:\n","        for samples_leaf in param_grid[\"min_samples_leaf\"]:\n","            for n_features in param_grid['n_features_to_select']:\n","                # Criar modelo\n","                dtc_test = DecisionTreeClassifier(criterion=\"entropy\", \n","                                             max_depth=depth, \n","                                             min_samples_split=samples_split,\n","                                             min_samples_leaf=samples_leaf)\n","\n","                # Determinar atributos a remover\n","                rfe_dtc = RFE(estimator=dtc_test, n_features_to_select=n_features)\n","                rfe_dtc.fit(X_train,y_train)\n","                # 10-fold CV\n","                test_scores = cross_val_score(dtc_test,\n","                                              X=rfe_dtc.transform(X_train), # Usar apenas os features nao removidos pelo RFE\n","                                              y=y_train,\n","                                              cv=10)\n","                # Guardar scores\n","                scores[(depth,samples_split,samples_leaf,n_features)] = [np.mean(test_scores), np.std(test_scores)]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Os melhores parâmetros encontrados para este problema:\n"," - n_features_to_select = 7\n"," - max_depth = 6\n"," - min_samples_split = 22\n"," - min_samples_leaf = 2\n","Average CV accuracy: 0.523 +/- 0.060\n"]}],"source":["best_param = max(scores, key=scores.get)\n","print(\"Os melhores parâmetros encontrados para este problema:\")\n","print(f\" - n_features_to_select = {best_param[3]}\\n - max_depth = {best_param[0]}\\n - min_samples_split = {best_param[1]}\\n - min_samples_leaf = {best_param[2]}\")\n","print(f\"Average CV accuracy: {scores[best_param][0]:.3f} +/- {scores[best_param][1]:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Conseguimos assim melhorar significativamente a accuracy média de CV do nosso classficador.  \n","\n","Vamos ver como se comporta como todos os dados de treino."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6534954407294833\n","Average CV accuracy: 0.523 +/- 0.060\n"]}],"source":["# Melhores parametros (para nao termos de correr a procura de novo sempre que executamos a celula)\n","features, depth, split, leaf = 7, 6, 22, 2\n","\n","# Criar modelo\n","dtc_best = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, min_samples_split=split, min_samples_leaf=leaf)\n","# Reduzir features\n","rfe_dtc_best = RFE(dtc_best, n_features_to_select=features)\n","rfe_dtc_best.fit(X_train, y_train)\n","# Treinar modelo\n","dtc_best.fit(rfe_dtc_best.transform(X_train),y_train)\n","# Calcular score\n","test_scores = cross_val_score(dtc_best,\n","                              X=rfe_dtc_best.transform(X_train),\n","                              y=y_train,\n","                              cv=10)\n","dtc_final = dtc_best.score(rfe_dtc_best.transform(X_train),y_train)\n","\n","# Guardar scores\n","dtc_cv_final = [np.mean(test_scores), np.std(test_scores)]\n","scores_finais[\"DecisionTree\"] = [dtc_final, dtc_cv_final]\n","# Display scores\n","print(\"Accuracy:\", dtc_final)\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(test_scores), np.std(test_scores)))"]},{"cell_type":"markdown","metadata":{},"source":["### k-NN"]},{"cell_type":"markdown","metadata":{},"source":["Vamos agora criar um modelo utilizando o classificador K-Nearest Neighbors e avaliar a sua performance no conjunto de treino sem alterar parâmetros"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV accuracy:\n","\t0.24242424242424243\n","\t0.3939393939393939\n","\t0.30303030303030304\n","\t0.3333333333333333\n","\t0.42424242424242425\n","\t0.3939393939393939\n","\t0.3333333333333333\n","\t0.45454545454545453\n","\t0.45454545454545453\n","\t0.5\n","Average CV accuracy: 0.383 +/- 0.075\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier()\n","\n","scores_knn = cross_val_score(knn,\n","                         X=X_train,\n","                         y=y_train,\n","                         cv=10\n","                        )\n","print('CV accuracy:', *scores_knn, sep='\\n\\t')\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores_knn), np.std(scores_knn)))"]},{"cell_type":"markdown","metadata":{},"source":["Como era de esperar o modelo sem ajustes não tem uma accuracy muito boa.  \n","  \n","Antes de alterar-mos parâmetros ou reduzir o número de atríbutos, vamos relembrar que o k-NN é altamente sensível à forma como são calculadas as distâncias, e portanto é fundamental que todos os atributos tenham valores em intervalos de igual amplitude.  \n","\n","Para a stardização, recorre-se ao método `StandardScaler` do scikit-learn, que corresponde a deslocar a distribuição de cada atributo de modo a ter uma média de zero e um desvio-padrão de 1, ie, para cada atributo vai subtrair-se a média e devidir pelo desvio-padrão."]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","X_train_normalizado = scaler.transform(X_train)"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV accuracy:\n","\t0.45454545454545453\n","\t0.2727272727272727\n","\t0.5909090909090909\n","\t0.45454545454545453\n","\t0.2727272727272727\n","\t0.5\n","\t0.45454545454545453\n","\t0.5\n","\t0.45454545454545453\n","\t0.45454545454545453\n","\t0.45454545454545453\n","\t0.5\n","\t0.6818181818181818\n","\t0.5\n","\t0.38095238095238093\n","Average CV accuracy: 0.462 +/- 0.100\n"]}],"source":["knn = KNeighborsClassifier()\n","\n","scores_knn = cross_val_score(knn,\n","                         X=X_train_normalizado,\n","                         y=y_train,\n","                         cv=15\n","                        )\n","print('CV accuracy:', *scores_knn, sep='\\n\\t')\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores_knn), np.std(scores_knn)))"]},{"cell_type":"markdown","metadata":{},"source":["Obtivemos um bom improvement na accuracy média do CV.  \n","\n","Podemos agora aplicar as mesmas técnicas que usamos no modelo do Decision Tree para melhorar-mos ainda mais o nosso classificador.  \n","\n","Para o caso do k-NN só temos os seguintes parâmetros do classificador para ajustar:\n","```python\n","n_neighbors\n","p\n","```\n","\n","Desta vez iremos utilizar o SequentialFeatureSelector que nos vai permitir obter os melhores features baseados na CV score do estimador fornecido a este método. Não usamos o RecursiveFeatureElimination aqui porque este necessita que o estimador seja capaz de atribuir pesos a cada um dos atributos para puder efetuar o ranking destes. No final ambos vão chegar ao mesmo objetivo que é eliminar features que não contribuem para a efetiva classificação dos dados.  \n","\n","Podemos ver rapidamente um exemplo do funcionamento do SequentialFeatureSelector"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["SequentialFeatureSelector(estimator=KNeighborsClassifier(), n_jobs=-1)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_selection import SequentialFeatureSelector\n","\n","\n","sfs_teste = SequentialFeatureSelector(KNeighborsClassifier(), n_jobs=-1)\n","sfs_teste.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Da mesma forma que o RFE vamos obter uma máscara que nos indica quais os features mais relevantes para este estimador."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["array([ True, False,  True,  True,  True, False, False,  True, False,\n","        True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        True, False, False, False, False, False, False, False, False,\n","       False, False, False, False])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["sfs_teste.support_"]},{"cell_type":"markdown","metadata":{},"source":["Voltamos agora à procura dos melhores parâmetros"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["from sklearn.feature_selection import SequentialFeatureSelector\n","\n","param_grid = {'n_neighbors' : [i for i in range(1,30)], 'p': [1,2]}\n","\n","scores_knn = {}\n","for neighbors in param_grid['n_neighbors']:\n","    for p in param_grid['p']:\n","            #Criar modelo\n","            knn_teste = KNeighborsClassifier(n_neighbors=neighbors, p=p)\n","            \n","            # Remover features automaticamente\n","            sfs_knn = SequentialFeatureSelector(knn_teste, n_jobs=-1)\n","            sfs_knn.fit(X_train_normalizado, y_train)\n","\n","            # 10-fold CV\n","            test_scores = cross_val_score(knn_teste,\n","                                          X=sfs_knn.transform(X_train_normalizado), # Usar apenas os features nao removidos pelo SFS\n","                                          y=y_train,\n","                                          cv=10)\n","            # Guardar scores\n","            scores_knn[(neighbors, p)] = [np.mean(test_scores), np.std(test_scores)]\n","            "]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Os melhores parâmetros encontrados para este problema:\n"," - n_neighbors = 23\n"," - p = 2\n","Average CV accuracy: 0.538 +/- 0.047\n"]}],"source":["best_param = max(scores_knn, key=scores_knn.get)\n","print(\"Os melhores parâmetros encontrados para este problema:\")\n","print(f\" - n_neighbors = {best_param[0]}\\n - p = {best_param[1]}\")\n","print(f\"Average CV accuracy: {scores_knn[best_param][0]:.3f} +/- {scores_knn[best_param][1]:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["E agora vamos ver como se comporta com os dados de treino completos"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.574468085106383\n","Average CV accuracy: 0.538 +/- 0.047\n"]}],"source":["# Melhores parametros\n","k, p = 23, 2\n","\n","# Criar modelo\n","knn_best = KNeighborsClassifier(n_neighbors=k, p = p)\n","# Remover features\n","sfs_knn_best = SequentialFeatureSelector(knn_best, n_jobs=-1)\n","sfs_knn_best.fit(X_train_normalizado, y_train)\n","# Treinar modelo\n","knn_best.fit(sfs_knn_best.transform(X_train_normalizado),y_train)\n","# Calcular score\n","test_scores = cross_val_score(knn_best,\n","                              X=sfs_knn_best.transform(X_train_normalizado),\n","                              y=y_train,\n","                              cv=10)\n","knn_final = knn_best.score(sfs_knn_best.transform(X_train_normalizado),y_train)\n","\n","# Guardar scores\n","knn_cv_final = [np.mean(test_scores), np.std(test_scores)]\n","scores_finais[\"k-NN\"] = [knn_final, knn_cv_final]\n","# Display scores\n","print(\"Accuracy:\", knn_final)\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(test_scores), np.std(test_scores)))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Naive Bayes"]},{"cell_type":"markdown","metadata":{},"source":["Vamos agora fazer o mesmo para o modelo Naive Bayes"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV accuracy:\n","\t0.30303030303030304\n","\t0.2727272727272727\n","\t0.2727272727272727\n","\t0.24242424242424243\n","\t0.36363636363636365\n","\t0.48484848484848486\n","\t0.36363636363636365\n","\t0.45454545454545453\n","\t0.2727272727272727\n","\t0.3125\n","Average CV accuracy: 0.334 +/- 0.078\n"]}],"source":["from sklearn.naive_bayes import GaussianNB\n","\n","nb_teste = GaussianNB()\n","nb_teste.fit(X_train, y_train)\n","\n","scores_nb = cross_val_score(nb_teste,\n","                            X=X_train,\n","                            y=y_train,\n","                            cv=10\n","                        )\n","print('CV accuracy:', *scores_nb, sep='\\n\\t')\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores_nb), np.std(scores_nb)))"]},{"cell_type":"markdown","metadata":{},"source":["Como não temos parâmetros para alterar no GaussiaNB, vamos recorrer simplesmente ao SequentialFeatureSelector para reduzir a dimensão das amostras e tentar simplificar a problema"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CV accuracy:\n","\t0.36363636363636365\n","\t0.48484848484848486\n","\t0.48484848484848486\n","\t0.36363636363636365\n","\t0.5757575757575758\n","\t0.6060606060606061\n","\t0.45454545454545453\n","\t0.45454545454545453\n","\t0.5151515151515151\n","\t0.4375\n","Average CV accuracy: 0.474 +/- 0.075\n"]}],"source":["from sklearn.feature_selection import SequentialFeatureSelector\n","\n","sfs_nb = SequentialFeatureSelector(estimator=nb_teste, n_jobs=-1)\n","sfs_nb.fit(X_train, y_train)\n","\n","scores_nb = cross_val_score(nb_teste,\n","                              X=sfs_nb.transform(X_train),\n","                              y=y_train,\n","                              cv=10)\n","\n","print('CV accuracy:', *scores_nb, sep='\\n\\t')\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(scores_nb), np.std(scores_nb)))"]},{"cell_type":"markdown","metadata":{},"source":["Obtemos um improvement bom na classificação, infelizmente não temos mais parâmetros para otimizar este classificador."]},{"cell_type":"markdown","metadata":{},"source":["E finalmente vamos aplicar ao conjunto completo dos dados de treino"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5258358662613982\n","Average CV accuracy: 0.474 +/- 0.075\n"]}],"source":["# Criar modelo\n","nb_best = GaussianNB()\n","# Remover features\n","sfs_nb_best = SequentialFeatureSelector(nb_best, n_jobs=-1)\n","sfs_nb_best.fit(X_train, y_train)\n","# Treinar modelo\n","nb_best.fit(sfs_nb_best.transform(X_train), y_train)\n","# Calcular score\n","test_scores = cross_val_score(nb_best,\n","                              X=sfs_nb_best.transform(X_train),\n","                              y=y_train,\n","                              cv=10)\n","nb_final = nb_best.score(sfs_nb_best.transform(X_train),y_train)\n","\n","# Guardar scores\n","nb_cv_final = [np.mean(test_scores), np.std(test_scores)]\n","scores_finais[\"GuassiaNB\"] = [nb_final, nb_cv_final]\n","# Display scores\n","print(\"Accuracy:\", nb_final)\n","print('Average CV accuracy: %.3f +/- %.3f' %(np.mean(test_scores), np.std(test_scores)))\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2. Seleção e apresentação do melhor modelo\n","\n","(remover) Apresentar todos os resultados para cada modelo obtido\n","\n","* Elencar o critério de selecção\n","* Apresentar a árvore (se aplicável)\n","* Discutir os resultados\n"]},{"cell_type":"markdown","metadata":{},"source":["Para determinar-mos o melhor dos classificadores temos de definir primeiro os nossos critérios de avaliação.  \n","\n","Selecionámos como critério principal a average CV accuracy de um teste de CV 10-fold, também vamos considerar a accuracy quando treinado com o conjunto completo de dados de treino.  \n","\n","Vamos então comparar os resultados obtidos para cada um dos classificadores"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Classificador</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTree</td>\n","      <td>0.653495</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>k-NN</td>\n","      <td>0.574468</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GuassiaNB</td>\n","      <td>0.525836</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Classificador  Accuracy\n","0  DecisionTree  0.653495\n","1          k-NN  0.574468\n","2     GuassiaNB  0.525836"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","accuracies_finais = list(map(lambda x: (x[0],x[1][0]), scores_finais.items()))\n","accuracies_cv_finais = list(map(lambda x: (x[0],float(x[1][1][0]),float(x[1][1][1])), scores_finais.items()))\n","\n","df_acc = pd.DataFrame(accuracies_finais, columns=[\"Classificador\", \"Accuracy\"])\n","df_acc"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Classificador</th>\n","      <th>Average CV Accuracy</th>\n","      <th>Desvio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTree</td>\n","      <td>0.522633</td>\n","      <td>0.060405</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>k-NN</td>\n","      <td>0.537973</td>\n","      <td>0.046563</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GuassiaNB</td>\n","      <td>0.474053</td>\n","      <td>0.074949</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Classificador  Average CV Accuracy    Desvio\n","0  DecisionTree             0.522633  0.060405\n","1          k-NN             0.537973  0.046563\n","2     GuassiaNB             0.474053  0.074949"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["df_acc_cv = pd.DataFrame(accuracies_cv_finais, columns=[\"Classificador\", \"Average CV Accuracy\", \"Desvio\"])\n","df_acc_cv"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y = list(map(lambda x: x[1], accuracies_cv_finais))\n","yerr = list(map(lambda x: x[2], accuracies_cv_finais))\n","\n","plt.errorbar(scores_finais.keys(), y, yerr=yerr,  fmt='s', color=\"black\")\n","plt.xlabel(\"Classificador\")\n","plt.ylabel(\"Average CV Accuracy\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Após analisar os dados pudemos concluir que o classificador DecisionTree obtém a melhor accuracy (por uma grande margem! 8%) quando treinado com todos os dados de treino disponíveis. O classificador k-NN apresenta a segunda melhor e o GuassianNB a pior. De acordo com as scores CV era de esperar que o k-NN estivesse mais perto (quase idênticos) do DecisionTree e se fosse-mos escolher apenas pela score CV seria díficil escolher o melhor, mas dado a diferença nas accuracies da classificação total teremos de considerar o classificador DecisionTree como o melhor dos três.  \n","\n","Esta diferença entre as scores totais e scores CV pode ser explicada simplesmente pela aleatoridade da CV, que apesar de repartir os dados em 10 segmentos no nosso caso, pode ainda apresentar resultados inconsistentes. Pois quando corrido várias vezes seguidas apresenta diferentes resultados (não muito diferentes entre si, mas diferentes na mesma).  \n","\n","Também temos de considerar que os métodos utilizados para reduzir o número de features nos dois casos foram diferentes, tendo sido utilizado o RecursiveFeatureElimination na DecisionTree e o SequencialFeatureSelector no k-NN. Apesar de ambos terem o mesmo objectivo o método como o alcançam é diferente e pode ultimamente influenciar os resultados quando comparados diretamente.  \n","\n","Finalmente, pelos resultados obtidos podemos também concluir que o classificador Naive Bayes não parece ser o mais indicado para este tipo de conjunto de dados."]},{"cell_type":"markdown","metadata":{},"source":["Concluindo, o classificador que decidimos selecionar para este problema é o DecisionTree\n","(Falta acabar aqui)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Validação do modelo final ajustado com um conjunto de validação independente\n","\n","(remover) O ficheiro `test.csv` contém um conjunto de dados não usado para treinar o modelo definido no ponto #2. \n","* Preparar o data set\n","* Correr o modelo selecionado como sendo o melhor nestes dados\n","* Apresentar os resultados para as métricas de validação\n","* Discutir os resultados alcançados confrontando os resultados com os obtidos anteriormente"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 4. Competição\n","\n","(remover) Explicar os passos feitos para chegar à solução submetida na competição, tendo em conta:\n","\n","* A escolha dos parâmetros usados pelos classificadores\n","* A escolha de atributos mais relevantes para a aprendizagem dos modelos\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"ca0a6ed6c3687464969dd6147ab8a98b55d02ef7a9aec76841b10aa7e05a39c3"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
